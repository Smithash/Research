{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22655,"status":"ok","timestamp":1731177456368,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"Lm3-LW2Apc7l","outputId":"87eeed2d-60e2-4290-d9c7-f2c2a853697d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14109,"status":"ok","timestamp":1731177470474,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"cf_-OYcspjFI","outputId":"8326b1e2-54e1-456e-b8ca-4d852096e2d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: huggingface-hub\u003e=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.24.7)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (10.4.0)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n","Collecting timm==0.9.7 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision\u003e=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (2.5.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4-\u003esegmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7-\u003esegmentation-models-pytorch) (6.0.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7-\u003esegmentation-models-pytorch) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (3.16.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (2024.10.0)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (2.32.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (4.12.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision\u003e=0.5.0-\u003esegmentation-models-pytorch) (1.26.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1-\u003etorch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (1.3.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (3.4.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.24.6-\u003esegmentation-models-pytorch) (2024.8.30)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003eefficientnet-pytorch==0.7.1-\u003esegmentation-models-pytorch) (3.0.2)\n","Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=a45718199a6e0ab70af33b4628d3fef5127cfd99f08c47ad2e76f66c1c365047\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=107c41b1348bd586728fb0c11a3dbb735ffcaa210569f5b0de0be3927bb622a1\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","  Attempting uninstall: timm\n","    Found existing installation: timm 1.0.11\n","    Uninstalling timm-1.0.11:\n","      Successfully uninstalled timm-1.0.11\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy\u003e1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging\u003e17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Requirement already satisfied: torch\u003e=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n","Collecting lightning-utilities\u003e=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003etorchmetrics) (75.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003etorchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1-\u003etorch\u003e=1.10.0-\u003etorchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.10.0-\u003etorchmetrics) (3.0.2)\n","Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.2\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n","Requirement already satisfied: click!=8.0.0,\u003e=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,\u003c6,\u003e=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n","Requirement already satisfied: typing-extensions\u003c5,\u003e=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n","Requirement already satisfied: six\u003e=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds\u003e=0.4.0-\u003ewandb) (1.16.0)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,\u003e=1.0.0-\u003ewandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.4.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2024.8.30)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003egitpython!=3.1.29,\u003e=1.0.0-\u003ewandb) (5.0.1)\n"]}],"source":["!pip install segmentation-models-pytorch\n","!pip install torchmetrics\n","!pip install wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26193,"status":"ok","timestamp":1731177496662,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"CpIwmIhGpkdC","outputId":"912f5fed-b901-45ea-f0dd-2b7737105348"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W\u0026B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["import numpy as np\n","from tqdm.notebook import tqdm\n","import scipy\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from skimage.transform import resize\n","import os\n","from torchmetrics import JaccardIndex\n","from torchmetrics.detection import IntersectionOverUnion\n","from segmentation_models_pytorch.losses import DiceLoss\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import os.path as osp\n","from torchvision import models\n","\n","\n","import wandb\n","\n","!wandb login"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1731177496662,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"e7Pf2M0Npm72"},"outputs":[],"source":["import os\n","import os.path as osp\n","\n","def get_matching_files(data_dir, phase):\n","    # List all image and mask files\n","    img_dir = osp.join(data_dir, phase, 'img')\n","    mask_dir = osp.join(data_dir, phase, 'mask')\n","\n","    # Get list of all files in the img and mask directories\n","    img_files = sorted(os.listdir(img_dir))\n","    mask_files = sorted(os.listdir(mask_dir))\n","\n","    # Initialize lists to store matched image-mask pairs\n","    image_list = []\n","    mask_list = []\n","\n","    # Iterate through image files and find corresponding mask\n","    for img_file in img_files:\n","        # Base name without extension\n","        base_name = img_file.split('.')[0]\n","\n","        # Try to find a matching mask with the same base name\n","        matching_mask = next((m for m in mask_files if m.startswith(base_name)), None)\n","\n","        if matching_mask:\n","            # Add the full path for both image and mask\n","            image_list.append(osp.join(img_dir, img_file))\n","            mask_list.append(osp.join(mask_dir, matching_mask))\n","        else:\n","            print(f\"Warning: No matching mask found for image {img_file}\")\n","\n","    return image_list, mask_list\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1731177496662,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"QvQArtNqpo9E"},"outputs":[],"source":["class OCTDataset(Dataset):\n","    def __init__(self, data_dir, phase, transforms):\n","        self.data_dir = data_dir\n","        self.phase = phase\n","        self.transforms = transforms\n","        self.image_list = None\n","        self.label_list = None\n","        self.read_lists()\n","\n","    def __getitem__(self, index):\n","        image_path = self.image_list[index]\n","        mask_path = self.label_list[index]\n","\n","        # Debugging: Ensure the pairing is correct\n","        # print(f\"Image: {image_path}, Mask: {mask_path}\")\n","\n","        image = Image.open(image_path).convert('RGB')\n","        label = Image.open(mask_path)\n","\n","        # Apply transformations\n","        data = list(self.transforms(image, label))\n","        image = data[0]\n","        label = data[1]\n","\n","        return image, label.long()\n","\n","    def __len__(self):\n","        return len(self.image_list)\n","\n","    def read_lists(self):\n","        # Get matching image and mask files\n","        self.image_list, self.label_list = get_matching_files(self.data_dir, self.phase)\n","        print(f\"Total number of {self.phase} images: {len(self.image_list)}\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1731177496662,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"LsIVJMxKprEb"},"outputs":[],"source":["import numpy as np\n","import torch\n","from PIL import Image\n","\n","class Label_Transform(object):\n","    def __init__(self, label_pixel=(26, 51, 77, 102, 128, 153, 179, 204, 230, 255)):\n","        self.label_pixel = label_pixel\n","\n","    def __call__(self, image, label, *args):\n","        label = np.array(label)\n","        for i in range(len(self.label_pixel)):\n","            label[label == self.label_pixel[i]] = i+1\n","\n","        # Ensure label array is of type uint8 and then convert to tensor\n","        label = label.astype(np.uint8)\n","        return image, torch.tensor(label, dtype=torch.long)\n","\n","\n","class Normalize(object):\n","    \"\"\"Given mean: (R, G, B) and std: (R, G, B),\n","    will normalize each channel of the torch.*Tensor, i.e.\n","    channel = (channel - mean) / std\n","    \"\"\"\n","\n","    def __init__(self, mean, std):\n","        self.mean = torch.FloatTensor(mean)\n","        self.std = torch.FloatTensor(std)\n","\n","    def __call__(self, image, label=None):\n","        for t, m, s in zip(image, self.mean, self.std):\n","            t.sub_(m).div_(s)\n","        if label is None:\n","            return image,\n","        else:\n","            return image, label\n","\n","class ToTensor(object):\n","    \"\"\"Converts a PIL.Image or numpy.ndarray (H x W x C) in the range\n","    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n","    \"\"\"\n","\n","    def __call__(self, pic, label=None):\n","        if isinstance(pic, np.ndarray):\n","            # handle numpy array\n","            img = torch.from_numpy(pic)\n","        else:\n","            # handle PIL Image\n","            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","            nchannel = len(pic.mode)\n","            img = img.view(pic.size[1], pic.size[0], nchannel)\n","            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n","        img = img.float().div(255)\n","        if label is None:\n","            return img,\n","        else:\n","            return img, label\n","\n","class Resize(object):\n","    def __init__(self, size):\n","        self.size = size  # Tuple (width, height) for the new size\n","\n","    def __call__(self, image, label=None):\n","        image = image.resize(self.size, Image.BILINEAR)  # Resize image using bilinear interpolation\n","        if label is not None:\n","            label = label.resize(self.size, Image.NEAREST)  # Resize mask using nearest-neighbor to preserve labels\n","        if label is None:\n","            return image,\n","        else:\n","            return image, label\n","\n","\n","\n","class Compose(object):\n","    \"\"\"Composes several transforms together.\n","    \"\"\"\n","\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","\n","    def __call__(self, *args):\n","        for t in self.transforms:\n","            args = t(*args)\n","        return args\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25283,"status":"ok","timestamp":1731177521941,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"99FJMTkaptHu","outputId":"2d229e06-e5a0-49cc-8ee5-5649e0f30e41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of train images: 148\n","Total number of eval images: 48\n","Total number of test images: 48\n","148\n"]},{"name":"stderr","output_type":"stream","text":["\u003cipython-input-6-52f76de3051b\u003e:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 512, 512])\n","torch.Size([16, 512, 512])\n"]}],"source":["from torch.utils.data import Subset\n","transforms = Compose([\n","    Resize((512, 512)),\n","    ToTensor(),\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    Label_Transform(),\n","\n","])\n","\n","\n","train_dataset = OCTDataset(data_dir = 'drive/My Drive/oct_dataset', phase = 'train',transforms = transforms)\n","val_dataset = OCTDataset(data_dir = 'drive/My Drive/oct_dataset', phase = 'eval', transforms = transforms)\n","test_dataset = OCTDataset(data_dir = 'drive/My Drive/oct_dataset', phase = 'test', transforms = transforms)\n","\n","#Choosing different sizes of dataset\n","train_size = len(train_dataset)\n","\n","\n","indices = list(range(train_size))\n","np.random.seed(42)  # Ensure reproducibility\n","# np.random.shuffle(indices)\n","split = int(np.floor(1 * train_size))  # Here is where u change the amount of data\n","train_indices = indices[:split]\n","\n","# Use Subset to create a dataset with only the selected indices\n","train_dataset = Subset(train_dataset, train_indices)\n","\n","print(len(train_dataset))\n","\n","\n","batch_size = 16\n","\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n","test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n","\n","#Example to see what the data shape is\n","for images, labels in train_loader:\n","  print(images.shape)\n","  print(labels.shape)\n","  break\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1731177521941,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"S15Lz0Q--grO"},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","# # Model\n","# class ResNetDeepLabV3(nn.Module):\n","#     def __init__(self, classes):\n","#         super(ResNetDeepLabV3, self).__init__()\n","#         self.classes = classes  # Store the number of classes\n","#         self.model = smp.DeepLabV3(\n","#             encoder_name=\"resnet50\",\n","#             encoder_weights= \"imagenet\",\n","#             in_channels = 3,\n","#             classes=self.classes,  # Set the number of classes\n","#             activation=None\n","#         )\n","\n","#     def forward(self, x):\n","#         return self.model(x)\n","\n","# model = ResNetDeepLabV3(classes = 11)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16923,"status":"ok","timestamp":1731177538860,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"WELglWk4pwt7","outputId":"8ef5afb2-c4b6-42a8-eaf3-6e2eadba17aa"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-9-5eea6aedef65\u003e:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  custom_weights = torch.load(custom_weights_path)\n"]},{"name":"stdout","output_type":"stream","text":["Custom weights loaded successfully!\n"]}],"source":["import torch\n","import segmentation_models_pytorch as smp\n","\n","def load_custom_weights_unet(model, custom_weights_path):\n","    # Load the custom weights\n","    custom_weights = torch.load(custom_weights_path)\n","\n","    # Get the state dict of the encoder\n","    encoder_state_dict = model.encoder.state_dict()\n","\n","    # Create a new state dict for the mapped weights\n","    new_state_dict = {}\n","\n","    # Define a mapping between custom weight keys and encoder keys\n","    key_mapping = {\n","        '0': 'firstconv',\n","        '1': 'firstbn',\n","        '4.0': 'layer1.0',\n","        '4.1': 'layer1.1',\n","        '4.2': 'layer1.2',\n","        '5.0': 'layer2.0',\n","        '5.1': 'layer2.1',\n","        '5.2': 'layer2.2',\n","        '5.3': 'layer2.3',\n","        '6.0': 'layer3.0',\n","        '6.1': 'layer3.1',\n","        '6.2': 'layer3.2',\n","        '6.3': 'layer3.3',\n","        '6.4': 'layer3.4',\n","        '6.5': 'layer3.5',\n","        '7.0': 'layer4.0',\n","        '7.1': 'layer4.1',\n","        '7.2': 'layer4.2',\n","    }\n","\n","    # Map the custom weights to the encoder structure\n","    for k, v in custom_weights['model'].items():\n","        for custom_key, encoder_key in key_mapping.items():\n","            if k.startswith(custom_key):\n","                new_key = k.replace(custom_key, encoder_key, 1)\n","                if new_key in encoder_state_dict:\n","                    new_state_dict[new_key] = v\n","\n","    # Load the mapped weights into the encoder\n","    model.encoder.load_state_dict(new_state_dict, strict=False)\n","\n","    return model\n","\n","# Create a U-Net model with a ResNet50 encoder\n","model = smp.DeepLabV3(\n","    encoder_name=\"resnet50\",\n","    encoder_weights=None,  # We'll load custom weights\n","    in_channels=3,\n","    classes=11\n",")\n","\n","# Load custom pretrained weights for the ResNet50 encoder\n","custom_weights_path = 'drive/My Drive/Colab Notebooks/SimCLR/No-Crop/best.pth'\n","model = load_custom_weights_unet(model, custom_weights_path)\n","\n","# Optionally move the model to GPU if needed\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","print(\"Custom weights loaded successfully!\")"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1731177538860,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"ar-OFc3apyaD"},"outputs":[],"source":["from torchmetrics.classification import Dice, JaccardIndex\n","import torch.nn.functional as F\n","class DiceLoss(nn.Module):\n","    def __init__(self, eps=1e-7, activation='softmax'):\n","        super().__init__()\n","        self.activation = activation\n","        self.eps = eps\n","\n","    def forward(self, y_pr, y_gt):\n","        if self.activation == 'softmax':\n","            y_pr = F.softmax(y_pr, dim=1)\n","        elif self.activation == 'sigmoid':\n","            y_pr = torch.sigmoid(y_pr)\n","\n","        num_classes = y_pr.shape[1]\n","        y_gt = F.one_hot(y_gt, num_classes=num_classes).permute(0, 3, 1, 2).float()\n","\n","        intersection = torch.sum(y_pr * y_gt, dim=[0, 2, 3])\n","        union = torch.sum(y_pr, dim=[0, 2, 3]) + torch.sum(y_gt, dim=[0, 2, 3])\n","\n","        dice = (2.0 * intersection + self.eps) / (union + self.eps)\n","        dice_loss = 1.0 - torch.mean(dice)\n","\n","        return dice_loss\n","\n","\n","class CEDiceLoss(nn.Module):\n","    def __init__(self, eps=1e-7, activation='softmax', lambda_dice=1.0, lambda_ce=1.0):\n","        super().__init__()\n","        self.dice_loss = DiceLoss(eps, activation)\n","        self.ce_loss = nn.CrossEntropyLoss(reduction='mean')\n","        self.lambda_dice = lambda_dice\n","        self.lambda_ce = lambda_ce\n","\n","    def forward(self, y_pr, y_gt):\n","        dice = self.dice_loss(y_pr, y_gt)\n","        ce = self.ce_loss(y_pr, y_gt)\n","        return self.lambda_dice * dice + self.lambda_ce * ce\n","\n","# Metrics\n","dice_coef = Dice(average='micro')\n","iou = JaccardIndex(task=\"multiclass\", num_classes=11)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":3403,"status":"ok","timestamp":1731177542255,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"K_pxfQfVp1F1","outputId":"956d4a70-11d3-4c9f-a5f4-027c038e3b04"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2455744\u001b[0m (\u001b[33m2455744-university-of-witwatersrand\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.5"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/wandb/run-20241109_183900-s6qlr6k1\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href='https://wandb.ai/2455744-university-of-witwatersrand/Final_Research/runs/s6qlr6k1' target=\"_blank\"\u003eDeepLabv3 SimCLR 100\u003c/a\u003e\u003c/strong\u003e to \u003ca href='https://wandb.ai/2455744-university-of-witwatersrand/Final_Research' target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href='https://wandb.me/run' target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at \u003ca href='https://wandb.ai/2455744-university-of-witwatersrand/Final_Research' target=\"_blank\"\u003ehttps://wandb.ai/2455744-university-of-witwatersrand/Final_Research\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at \u003ca href='https://wandb.ai/2455744-university-of-witwatersrand/Final_Research/runs/s6qlr6k1' target=\"_blank\"\u003ehttps://wandb.ai/2455744-university-of-witwatersrand/Final_Research/runs/s6qlr6k1\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbutton onClick=\"this.nextSibling.style.display='block';this.style.display='none';\"\u003eDisplay W\u0026B run\u003c/button\u003e\u003ciframe src='https://wandb.ai/2455744-university-of-witwatersrand/Final_Research/runs/s6qlr6k1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'\u003e\u003c/iframe\u003e"],"text/plain":["\u003cwandb.sdk.wandb_run.Run at 0x7df35159e200\u003e"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize W\u0026B\n","# Initialize W\u0026B\n","wandb.init(\n","    project=\"Final_Research\",\n","    config={\n","        \"learning_rate\": 1e-3,\n","        \"data size\" : 148\n","    },\n","    name=\"DeepLabv3 SimCLR 100\"\n","    )\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1731177542255,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"gZlAgQ8Lp3Jm"},"outputs":[],"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import wandb\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torchvision.utils import make_grid\n","from torchmetrics import Accuracy\n","\n","\n","def train(model, train_loader, val_loader, epochs, loss_fn, optimizer, device):\n","\n","\n","    best_val_loss = float('inf')\n","    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n","    patience = 20 # Early stopping patience\n","    patience_counter = 0\n","\n","    # Initialize metrics\n","    dice_metric = Dice(average='micro').to(device)\n","    iou_metric = JaccardIndex(task=\"multiclass\", num_classes=11).to(device)\n","    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=11).to(device)\n","\n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0.0\n","        train_dice = 0.0\n","        train_iou = 0.0\n","        train_acc = 0.0\n","\n","        for data, target in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n","            data, target = data.float().to(device), target.to(device)\n","            optimizer.zero_grad()\n","            # output = model(data)\n","            output = model(data)\n","\n","            loss = loss_fn(output, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","            with torch.no_grad():\n","                pred_labels = torch.argmax(output, dim=1)\n","                train_dice += dice_metric(pred_labels, target)\n","                train_iou += iou_metric(pred_labels, target)\n","                train_acc += accuracy_metric(pred_labels, target)\n","        #Averages\n","        train_loss /= len(train_loader)\n","        train_dice /= len(train_loader)\n","        train_iou /= len(train_loader)\n","        train_acc /= len(train_loader)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        val_dice = 0.0\n","        val_iou = 0.0\n","        val_acc =0.0\n","        with torch.no_grad():\n","            for data, target, *_ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n","                data, target = data.float().to(device), target.to(device)\n","                # output = model(data)\n","                output = model(data)\n","\n","                loss = loss_fn(output, target)\n","                val_loss += loss.item()\n","\n","                pred_labels = torch.argmax(output, dim=1)\n","                val_dice += dice_metric(pred_labels, target)\n","                val_iou += iou_metric(pred_labels, target)\n","                val_acc += accuracy_metric(pred_labels, target)\n","\n","        val_loss /= len(val_loader)\n","        val_dice /= len(val_loader)\n","        val_iou /= len(val_loader)\n","        val_acc /= len(val_loader)\n","\n","        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, Train IoU: {train_iou:.4f}, \"\n","              f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, Val IoU: {val_iou:.4f}\")\n","\n","        # Learning rate scheduling\n","        scheduler.step(val_loss)\n","\n","        # Model checkpointing\n","        if val_loss \u003c best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), 'drive/MyDrive/Colab Notebooks/DeepLabV3 SimCLR/Best_model_100.pth')\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        # Early stopping\n","        if patience_counter \u003e= patience:\n","            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n","            break\n","\n","        # Log metrics to W\u0026B\n","        wandb.log({\n","            \"Epoch\": epoch + 1,\n","            \"Train Loss\": train_loss,\n","            \"Train Dice\": train_dice,\n","            \"Train IoU\": train_iou,\n","            \"Train Accuracy\": train_acc,\n","            \"Val Loss\": val_loss,\n","            \"Val Dice\": val_dice,\n","            \"Val IoU\": val_iou,\n","            \"Val Accuracy\": val_acc,\n","            \"Learning Rate\": optimizer.param_groups[0]['lr']\n","        })\n","\n","    # wandb.finish()\n","    return model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1731177542255,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"PzYj-hdOp554"},"outputs":[],"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def visualize_results(model, data_loader, device, num_samples=5, class_colors=None):\n","    model.eval()\n","    images, targets, predictions = [], [], []\n","\n","    with torch.no_grad():\n","        for data, target, *_ in data_loader:\n","            if len(images) \u003e= num_samples:\n","                break\n","            data, target = data.float().to(device), target.long().to(device)\n","            output = model(data)\n","            pred = torch.argmax(output, dim=1)\n","\n","            images.extend(data.cpu())\n","            targets.extend(target.cpu())\n","            predictions.extend(pred.cpu())\n","\n","    images = images[:num_samples]\n","    targets = targets[:num_samples]\n","    predictions = predictions[:num_samples]\n","\n","    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n","\n","    for i in range(num_samples):\n","        # Original Image\n","        img = images[i].permute(1, 2, 0).numpy()\n","        if img.min() \u003c 0 or img.max() \u003e 1:  # Check if image needs normalization adjustment\n","            img = (img - img.min()) / (img.max() - img.min())  # Normalize to [0, 1]\n","        axs[i, 0].imshow(img)\n","        axs[i, 0].set_title('Original Image')\n","        axs[i, 0].axis('off')\n","\n","        # Ground Truth\n","        gt_mask = targets[i].squeeze().numpy()\n","        if class_colors:\n","            gt_colored = np.zeros((gt_mask.shape[0], gt_mask.shape[1], 3), dtype=np.uint8)\n","            for class_idx, color in enumerate(class_colors):\n","                gt_colored[gt_mask == class_idx] = color\n","            axs[i, 1].imshow(gt_colored)\n","        else:\n","            axs[i, 1].imshow(gt_mask, cmap='gray')  # Use grayscale if no colors provided\n","        axs[i, 1].set_title('Ground Truth')\n","        axs[i, 1].axis('off')\n","\n","        # Prediction\n","        pred_mask = predictions[i].squeeze().numpy()\n","        if class_colors:\n","            pred_colored = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)\n","            for class_idx, color in enumerate(class_colors):\n","                pred_colored[pred_mask == class_idx] = color\n","            axs[i, 2].imshow(pred_colored)\n","        else:\n","            axs[i, 2].imshow(pred_mask, cmap='gray')  # Use grayscale if no colors provided\n","        axs[i, 2].set_title('Prediction')\n","        axs[i, 2].axis('off')\n","\n","    plt.tight_layout()\n","    return fig\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514469,"status":"ok","timestamp":1731178959054,"user":{"displayName":"Dorina Smith","userId":"11414141084372751589"},"user_tz":-120},"id":"h7oFSV-np7pX"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n","Epoch 1/100 - Training: 100%|██████████| 10/10 [04:49\u003c00:00, 28.92s/it]\n","Epoch 1/100 - Validation: 100%|██████████| 3/3 [01:09\u003c00:00, 23.10s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1: Train Loss: 1.3405, Train Dice: 0.7644, Train IoU: 0.1434, Val Loss: 0.9948, Val Dice: 0.8721, Val IoU: 0.0793\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 2/100 - Validation: 100%|██████████| 3/3 [00:03\u003c00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2: Train Loss: 0.4701, Train Dice: 0.9175, Train IoU: 0.2297, Val Loss: 0.6540, Val Dice: 0.8721, Val IoU: 0.0793\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.02s/it]\n","Epoch 3/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3: Train Loss: 0.2791, Train Dice: 0.9269, Train IoU: 0.2704, Val Loss: 0.4133, Val Dice: 0.8846, Val IoU: 0.1237\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.02s/it]\n","Epoch 4/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4: Train Loss: 0.2050, Train Dice: 0.9368, Train IoU: 0.3256, Val Loss: 0.2617, Val Dice: 0.9193, Val IoU: 0.2642\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.02s/it]\n","Epoch 5/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5: Train Loss: 0.1726, Train Dice: 0.9433, Train IoU: 0.3941, Val Loss: 0.2276, Val Dice: 0.9234, Val IoU: 0.2919\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.01s/it]\n","Epoch 6/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6: Train Loss: 0.1512, Train Dice: 0.9486, Train IoU: 0.4491, Val Loss: 0.1734, Val Dice: 0.9458, Val IoU: 0.4645\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.01s/it]\n","Epoch 7/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7: Train Loss: 0.1354, Train Dice: 0.9536, Train IoU: 0.4937, Val Loss: 0.1600, Val Dice: 0.9474, Val IoU: 0.4721\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.02s/it]\n","Epoch 8/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8: Train Loss: 0.1257, Train Dice: 0.9559, Train IoU: 0.5174, Val Loss: 0.1596, Val Dice: 0.9451, Val IoU: 0.4658\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.01s/it]\n","Epoch 9/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9: Train Loss: 0.1193, Train Dice: 0.9563, Train IoU: 0.5169, Val Loss: 0.1608, Val Dice: 0.9451, Val IoU: 0.4757\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 10/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10: Train Loss: 0.1141, Train Dice: 0.9586, Train IoU: 0.5509, Val Loss: 0.1492, Val Dice: 0.9499, Val IoU: 0.5147\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.01s/it]\n","Epoch 11/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11: Train Loss: 0.1054, Train Dice: 0.9616, Train IoU: 0.5683, Val Loss: 0.1528, Val Dice: 0.9466, Val IoU: 0.4799\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 12/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12: Train Loss: 0.1005, Train Dice: 0.9630, Train IoU: 0.5752, Val Loss: 0.1413, Val Dice: 0.9528, Val IoU: 0.5447\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.01s/it]\n","Epoch 13/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13: Train Loss: 0.0969, Train Dice: 0.9642, Train IoU: 0.5872, Val Loss: 0.1525, Val Dice: 0.9485, Val IoU: 0.5110\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 14/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14: Train Loss: 0.0970, Train Dice: 0.9635, Train IoU: 0.5897, Val Loss: 0.1491, Val Dice: 0.9481, Val IoU: 0.4756\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 15/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15: Train Loss: 0.0918, Train Dice: 0.9652, Train IoU: 0.5995, Val Loss: 0.1548, Val Dice: 0.9467, Val IoU: 0.5046\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 16/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16: Train Loss: 0.0889, Train Dice: 0.9661, Train IoU: 0.6045, Val Loss: 0.1550, Val Dice: 0.9463, Val IoU: 0.4900\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 17/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: Train Loss: 0.0851, Train Dice: 0.9677, Train IoU: 0.6226, Val Loss: 0.1582, Val Dice: 0.9421, Val IoU: 0.4361\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.98s/it]\n","Epoch 18/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: Train Loss: 0.0821, Train Dice: 0.9688, Train IoU: 0.6298, Val Loss: 0.1379, Val Dice: 0.9534, Val IoU: 0.5407\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.02s/it]\n","Epoch 19/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: Train Loss: 0.0796, Train Dice: 0.9694, Train IoU: 0.6307, Val Loss: 0.1399, Val Dice: 0.9521, Val IoU: 0.5416\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 20/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: Train Loss: 0.0804, Train Dice: 0.9683, Train IoU: 0.6225, Val Loss: 0.1493, Val Dice: 0.9483, Val IoU: 0.4942\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 21/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21: Train Loss: 0.0789, Train Dice: 0.9688, Train IoU: 0.6235, Val Loss: 0.1564, Val Dice: 0.9502, Val IoU: 0.5180\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 22/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22: Train Loss: 0.0737, Train Dice: 0.9713, Train IoU: 0.6444, Val Loss: 0.1426, Val Dice: 0.9511, Val IoU: 0.5177\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 23/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23: Train Loss: 0.0738, Train Dice: 0.9707, Train IoU: 0.6387, Val Loss: 0.1433, Val Dice: 0.9542, Val IoU: 0.5560\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 24/100 - Validation: 100%|██████████| 3/3 [00:03\u003c00:00,  1.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24: Train Loss: 0.0699, Train Dice: 0.9726, Train IoU: 0.6623, Val Loss: 0.1471, Val Dice: 0.9525, Val IoU: 0.5591\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 25/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25: Train Loss: 0.0642, Train Dice: 0.9755, Train IoU: 0.6903, Val Loss: 0.1309, Val Dice: 0.9588, Val IoU: 0.5981\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 26/100 - Training: 100%|██████████| 10/10 [00:20\u003c00:00,  2.02s/it]\n","Epoch 26/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26: Train Loss: 0.0629, Train Dice: 0.9761, Train IoU: 0.6975, Val Loss: 0.1317, Val Dice: 0.9588, Val IoU: 0.5962\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 27/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 27/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27: Train Loss: 0.0607, Train Dice: 0.9771, Train IoU: 0.6994, Val Loss: 0.1284, Val Dice: 0.9593, Val IoU: 0.6028\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 28/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.98s/it]\n","Epoch 28/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28: Train Loss: 0.0594, Train Dice: 0.9779, Train IoU: 0.7095, Val Loss: 0.1306, Val Dice: 0.9590, Val IoU: 0.6006\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 29/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 29/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29: Train Loss: 0.0587, Train Dice: 0.9781, Train IoU: 0.7122, Val Loss: 0.1311, Val Dice: 0.9591, Val IoU: 0.6002\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 30/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 30/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30: Train Loss: 0.0580, Train Dice: 0.9783, Train IoU: 0.7083, Val Loss: 0.1308, Val Dice: 0.9593, Val IoU: 0.6041\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 31/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 31/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31: Train Loss: 0.0570, Train Dice: 0.9789, Train IoU: 0.7160, Val Loss: 0.1331, Val Dice: 0.9591, Val IoU: 0.6009\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 32/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 32/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 32: Train Loss: 0.0562, Train Dice: 0.9791, Train IoU: 0.7163, Val Loss: 0.1317, Val Dice: 0.9595, Val IoU: 0.6062\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 33/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 33/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 33: Train Loss: 0.0558, Train Dice: 0.9794, Train IoU: 0.7205, Val Loss: 0.1329, Val Dice: 0.9592, Val IoU: 0.6020\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 34/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 34/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 34: Train Loss: 0.0556, Train Dice: 0.9794, Train IoU: 0.7192, Val Loss: 0.1333, Val Dice: 0.9593, Val IoU: 0.6034\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 35/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 35/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35: Train Loss: 0.0551, Train Dice: 0.9796, Train IoU: 0.7213, Val Loss: 0.1333, Val Dice: 0.9594, Val IoU: 0.6045\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 36/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 36/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36: Train Loss: 0.0555, Train Dice: 0.9795, Train IoU: 0.7206, Val Loss: 0.1336, Val Dice: 0.9595, Val IoU: 0.6052\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 37/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 37/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 37: Train Loss: 0.0558, Train Dice: 0.9793, Train IoU: 0.7200, Val Loss: 0.1334, Val Dice: 0.9594, Val IoU: 0.6052\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 38/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 38/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 38: Train Loss: 0.0554, Train Dice: 0.9795, Train IoU: 0.7225, Val Loss: 0.1335, Val Dice: 0.9594, Val IoU: 0.6047\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 39/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.97s/it]\n","Epoch 39/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39: Train Loss: 0.0557, Train Dice: 0.9792, Train IoU: 0.7178, Val Loss: 0.1337, Val Dice: 0.9593, Val IoU: 0.6050\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 40/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 40/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 40: Train Loss: 0.0553, Train Dice: 0.9796, Train IoU: 0.7234, Val Loss: 0.1337, Val Dice: 0.9594, Val IoU: 0.6049\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 41/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 41/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 41: Train Loss: 0.0557, Train Dice: 0.9793, Train IoU: 0.7160, Val Loss: 0.1340, Val Dice: 0.9594, Val IoU: 0.6050\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 42/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 42/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42: Train Loss: 0.0552, Train Dice: 0.9795, Train IoU: 0.7206, Val Loss: 0.1340, Val Dice: 0.9594, Val IoU: 0.6051\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 43/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.95s/it]\n","Epoch 43/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43: Train Loss: 0.0552, Train Dice: 0.9797, Train IoU: 0.7248, Val Loss: 0.1338, Val Dice: 0.9594, Val IoU: 0.6055\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 44/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 44/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44: Train Loss: 0.0553, Train Dice: 0.9796, Train IoU: 0.7243, Val Loss: 0.1337, Val Dice: 0.9594, Val IoU: 0.6052\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 45/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 45/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 45: Train Loss: 0.0549, Train Dice: 0.9797, Train IoU: 0.7227, Val Loss: 0.1337, Val Dice: 0.9594, Val IoU: 0.6050\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 46/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 46/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 46: Train Loss: 0.0556, Train Dice: 0.9795, Train IoU: 0.7214, Val Loss: 0.1338, Val Dice: 0.9594, Val IoU: 0.6050\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 47/100 - Training: 100%|██████████| 10/10 [00:19\u003c00:00,  1.96s/it]\n","Epoch 47/100 - Validation: 100%|██████████| 3/3 [00:02\u003c00:00,  1.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 47: Train Loss: 0.0555, Train Dice: 0.9795, Train IoU: 0.7208, Val Loss: 0.1338, Val Dice: 0.9594, Val IoU: 0.6047\n","Early stopping triggered after 47 epochs\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Define your model, loss function, optimizer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = model.to(device)\n","loss_fn = CEDiceLoss(lambda_dice=0, lambda_ce=1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Train the model\n","trained_model = train(model, train_loader, val_loader, epochs=100, loss_fn=loss_fn, optimizer=optimizer, device=device)\n","\n","# Define class colors (adjust according to your classes)\n","class_colors = [\n","    [0, 0, 0],        # Class 0 (black)\n","    [255, 0, 0],      # Class 1 (red)\n","    [0, 255, 0],      # Class 2 (green)\n","    [0, 0, 255],      # Class 3 (blue)\n","    [255, 255, 0],    # Class 4 (yellow)\n","    [255, 0, 255],    # Class 5 (magenta)\n","    [0, 255, 255],    # Class 6 (cyan)\n","    [192, 192, 192],  # Class 7 (silver)\n","    [128, 0, 0],      # Class 8 (maroon)\n","    [128, 128, 0],    # Class 9 (olive)\n","    [0, 128, 0]       # Class 10 (dark green)\n","]\n","\n","# Visualize results after training\n","# fig = visualize_results(trained_model, val_loader, device, num_samples=5, class_colors=class_colors)\n","# plt.show()\n","\n","# # Log the visualization to W\u0026B\n","# wandb.init(project=\"Final_Research\", name=\"Post_Training_Visualisation_DeepLabv3_ImageNet_100\")\n","# wandb.log({\"Validation Predictions DeepLabv3 ImageNet 100\": wandb.Image(fig)})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JC0Q9gHhp9ig","outputId":"8ceb919d-1226-477b-ea5b-76d7ba7dbb66"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-15-3175d33043ad\u003e:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('drive/MyDrive/Colab Notebooks/DeepLabV3 SimCLR/Best_model_100.pth'))\n","Testing:   0%|          | 0/3 [00:00\u003c?, ?it/s]"]}],"source":["from tqdm import tqdm\n","\n","def test(model, test_loader, loss_fn, device):\n","    model.eval()  # Set model to evaluation mode\n","    test_loss = 0.0\n","    test_dice = 0.0\n","    test_iou = 0.0\n","    test_acc =0.0\n","\n","    dice_metric = Dice(average='micro').to(device)\n","    iou_metric = JaccardIndex(task=\"multiclass\", num_classes=11).to(device)  # Adjust num_classes as needed\n","    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=11).to(device)\n","    with torch.no_grad():  # Disable gradient computation\n","        for data, target, *_ in tqdm(test_loader, desc=\"Testing\"):\n","            data, target = data.float().to(device), target.to(device)\n","\n","            # Forward pass\n","            output = model(data)\n","            loss = loss_fn(output, target)\n","            test_loss += loss.item()\n","\n","            # Get predictions\n","            pred_labels = torch.argmax(output, dim=1)\n","\n","            # Calculate metrics\n","            test_dice += dice_metric(pred_labels, target)\n","            test_iou += iou_metric(pred_labels, target)\n","            test_acc += accuracy_metric(pred_labels, target)\n","\n","    # Average metrics over all batches\n","    test_loss /= len(test_loader)\n","    test_dice /= len(test_loader)\n","    test_iou /= len(test_loader)\n","    test_acc /= len(test_loader)\n","\n","    print(f\"Test Loss: {test_loss:.4f}, Test Dice: {test_dice:.4f}, Test IoU: {test_iou:.4f}\")\n","\n","    return test_loss, test_dice, test_iou, test_acc\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# model = DeepLabV3(classes = 11).to(device)\n","model.load_state_dict(torch.load('drive/MyDrive/Colab Notebooks/DeepLabV3 SimCLR/Best_model_100.pth'))\n","loss_fn = CEDiceLoss(lambda_dice=0, lambda_ce=1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Run the test function\n","test_loss, test_dice, test_iou, test_acc = test(model, test_loader, loss_fn, device)\n","\n","# Optionally, log test results to W\u0026B\n","wandb.init(project=\"Final_Research\", name=\"Test_Results_DeepLabv3_SimCLR_100\")\n","wandb.log({\n","    \"Test Loss\": test_loss,\n","    \"Test Dice\": test_dice,\n","    \"Test IoU\": test_iou,\n","    \"Test Accuracy\": test_acc\n","})\n","wandb.finish()\n","\n","# fig = visualize_results(trained_model, test_loader, device, num_samples=5, class_colors=class_colors)\n","# plt.show()\n","\n","# # Log the visualization to W\u0026B\n","# wandb.init(project=\"Final_Research\", name=\"Test_Visualization_DeepLabv3_ImageNet_10\")\n","# wandb.log({\"Final Predictions: DeepLabv3 ImageNet 100\": wandb.Image(fig)})\n","# wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNURQTk8rJ5XTqERUh6tQdN","gpuType":"L4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}